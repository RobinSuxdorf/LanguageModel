{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- setuptools, requirements\n",
    "- separate model and generation\n",
    "- interface for generation/chat\n",
    "- eos tokens\n",
    "- google style guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "context_length = 256\n",
    "embed_size = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "forward_expansion = 4\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/shakespeare.txt') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import bpe_tokenizer\n",
    "from pipelines import text_to_tensor\n",
    "\n",
    "text = text[:10000]\n",
    "\n",
    "tokenizer = bpe_tokenizer.BytePairEncodingTokenizer.read_pkl('./tokenizer/trained_tokenizers/bpe.pkl')\n",
    "\n",
    "pipeline = text_to_tensor.create_pipeline(tokenizer, 0.9)\n",
    "\n",
    "train_data, test_data = pipeline.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from language_model import generation\n",
    "\n",
    "model = generation.LanguageModel(\n",
    "    tokenizer,\n",
    "    embed_size,\n",
    "    context_length,\n",
    "    num_layers,\n",
    "    num_heads,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    device\n",
    ")\n",
    "\n",
    "print(sum([p.numel() for p in model.encoder.parameters()]) / 1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(' ', max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from language_model import train\n",
    "\n",
    "args = train.TrainArgs()\n",
    "\n",
    "trainer = train.ModelTrainer(args, model, train_data, test_data)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(' ', 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
