# Language Model Project

Welcome to my Language Model project! This repository contains my own custom language model, built with a focus on an encoder-only architecture that utilizes the attention mechanism. I've learned a lot from the tutorials by Andrej Karpathy and have been inspired by the Llama source code.

## Next Ideas

The primary goals for this project include:

1. **Setuptools and Requirements**: Creating a robust Python package with `setuptools` for easy installation and defining the required dependencies in a `requirements.txt` file.

2. **Interface for Generation/Chat**: Building a user-friendly interface that allows users to interact with and generate text from your language model. 

3. **End-of-Sentence (EOS) Tokens**: Implementing end-of-sentence tokens to improve the model's understanding of sentence boundaries and improve text generation.

4. **Word Embeddings**: Extract word embedding from the language model.

5. **Tokenizer in C++**: Developing a fast and efficient text tokenizer in C++ to accelerate text processing, which is particularly important for large-scale text generation tasks.
